# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #1 выполнил:

+ Несмиянов Матвей Андреевич
+ РИ-210930 Отметка о выполнении заданий (заполняется студентом):

| Задание  | Выполнение | Баллы |
| ------------- | ------------- | ------------- |
| Задание 1 | * | 60 | 
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:

+ к.т.н., доцент Денисов Д.В.
+ к.э.н., доцент Панов М.А.
+ ст. преп., Фадеев В.О.


Структура отчета

+ Данные о работе: название работы, фио, группа, выполненные задания.
+ Цель работы.
+ Задание 1.
  + Код реализации выполнения задания. Визуализация результатов выполнения.
+ Задание 2.
  + Код реализации выполнения задания. Визуализация результатов выполнения.
+ Задание 3.
  + Код реализации выполнения задания. Визуализация результатов выполнения.
+ Выводы.

# Цель работы

Ознакомиться с основными операторами зыка Python на примере реализации линейной регрессии.

# Задание 1.

+ Скриншоты выполнения скрипта в google.colab и сохранения его на гугл диск:

![image](https://user-images.githubusercontent.com/94855641/205319762-195d44e1-9084-4b73-862f-5ccc9bbf061b.png)

![2](https://user-images.githubusercontent.com/94855641/205320156-704494ae-9432-4b81-a378-a82e1b78091c.png)

+ Hello World в Unity:

![3](https://user-images.githubusercontent.com/94855641/205320416-ea1174af-cb3a-4ff6-8f70-433f8980864a.png)

# Задание 2

+ Подготовка данных для алгоритма линейной регрессии

![4](https://user-images.githubusercontent.com/94855641/205320741-e9779d29-7e44-4950-a3e4-f1b619b99fea.png)

+ Определение функций модели, потери и оптимизации

<img width="1771" alt="5" src="https://user-images.githubusercontent.com/94855641/205321025-4a27e98f-2b34-4db4-96ec-2a3d54b7e0e8.png">

+ Инициализация гиперпараметров модели и 1 итерация

![6](https://user-images.githubusercontent.com/94855641/205321142-cba87567-38ef-4e99-951b-621239f1a9f3.png)

+ 2 итерации

![7](https://user-images.githubusercontent.com/94855641/205321251-6008bb5d-e7f9-4678-b61b-fd97049f71a6.png)

+ 3 итерации

![8](https://user-images.githubusercontent.com/94855641/205321346-fa0533ed-79a8-45e0-969b-58595c5bcdb3.png)

+ 4 итерации

![9](https://user-images.githubusercontent.com/94855641/205321417-a4d286f7-d215-4a0d-bffb-776a203cd5de.png)

+ 5 итераций

![10](https://user-images.githubusercontent.com/94855641/205321510-cde5aedf-1ddd-48bf-ba57-2d48c77da362.png)

+ 1000 итераций

![11](https://user-images.githubusercontent.com/94855641/205321591-39261bf5-cee0-4ada-80d3-90be81a2fd6d.png)

Код задания находится в этом репозитории

# Задание 3

# Должна ли величина loss стремиться к нулю при изменении исходных данных?

+ Прежде всего надо сказать, что loss - среднеквадратичное отклонение(ошибка). Величина loss может стремиться к нулю при изменении исходных данных. Чтобы показать это, я присвоил переменной `y` значение переменной `x`, домноженное на коэффициент 2.

![12](https://user-images.githubusercontent.com/94855641/205322183-63827ffc-0ff5-4181-bc54-13cc1056a617.png)

+ Полученный результат через 10000 итераций:

![13](https://user-images.githubusercontent.com/94855641/205322277-d5a69b82-952c-44b6-be9b-c00a1ac561c3.png)

# Какова роль параметра Lr?

+ Параметр Lr можно расшифровать как learning rate, в переводе на русский - скорость обучения. Меняя этот параметр, мы как бы меняем скорость изменения весов(насколько я это понял). Особенно это заметно на небольшом количестве итераций. В качестве примера я взял модель из Задания 1 с теми же исходными данными

![14](https://user-images.githubusercontent.com/94855641/205322402-6cc4610c-22cc-4d9d-8b57-a7209c411827.png)
![15](https://user-images.githubusercontent.com/94855641/205322438-465f2f32-3d4a-4e3f-81df-6c0fc8415d34.png)

На первом скриншоте среднеквадратичное отклонение больше, чем на втором, потому что длина шага оказалась слишком мала, чтобы функция оптимизации успела отработать корректно.

# Выводы

В данной лабораторной работе я познакомился с интерфейсом google.colab и Unity. Также я изучил алгоритм линейной регрессии

# Powered by

BigDigital Team: Denisov | Fadeev | Panov
